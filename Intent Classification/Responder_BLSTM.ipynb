{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmLCyKLCIHpD",
        "outputId": "92ec5302-4434-4666-a54f-d8fdfcb73b89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the dataset\n",
        "train_df = pd.read_csv('train.csv')\n",
        "qa_df = pd.read_csv('QA_data.csv', encoding='ISO-8859-1')\n",
        "\n",
        "# Define a function to normalize and tokenize the text\n",
        "def normalize_and_tokenize(text):\n",
        "    # Remove special characters and punctuation symbols\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "# Apply the function to the 'text' column\n",
        "train_df['text'] = train_df['text'].apply(normalize_and_tokenize)\n",
        "qa_df['text'] = qa_df['text'].apply(normalize_and_tokenize)\n",
        "qa_df['answer'] = qa_df['answer'].apply(normalize_and_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip glove.6B.300d.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPDF4Hz4JhfW",
        "outputId": "67ba6284-7438-4597-fb94-d5a5658f4ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-19 17:54:36--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-05-19 17:54:36--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-05-19 17:54:36--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2023-05-19 17:57:16 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the pre-trained GloVe embeddings\n",
        "embeddings_index = {}\n",
        "with open('glove.6B.300d.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "# Define a function to get the embedding for a given word\n",
        "def get_embedding(word):\n",
        "    embedding = embeddings_index.get(word)\n",
        "    if embedding is not None:\n",
        "        return embedding\n",
        "    else:\n",
        "        return np.zeros(300)\n",
        "\n",
        "# Define a function to get the embeddings for a given text\n",
        "def get_text_embeddings(text):\n",
        "    embeddings = []\n",
        "    for word in text:\n",
        "        embedding = get_embedding(word)\n",
        "        embeddings.append(embedding)\n",
        "    return embeddings\n",
        "\n",
        "# Apply the function to the 'text' column of the train and test datasets\n",
        "train_df['text_embeddings'] = train_df['text'].apply(get_text_embeddings)\n",
        "qa_df['text_embeddings'] = qa_df['text'].apply(get_text_embeddings)\n",
        "qa_df['answer_embeddings'] = qa_df['answer'].apply(get_text_embeddings)"
      ],
      "metadata": {
        "id": "6BkBrI4wJkM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Bidirectional, LSTM, Dense\n",
        "from keras.utils import to_categorical\n",
        "!pip install keras_preprocessing\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the number of classes\n",
        "num_coarse_classes = 6\n",
        "num_fine_classes = 50\n",
        "\n",
        "# Convert the 'label-coarse' and 'label-fine' columns to one-hot encoded labels\n",
        "y_coarse = to_categorical(qa_df['label-coarse'], num_classes=num_coarse_classes)\n",
        "y_fine = to_categorical(qa_df['label-fine'], num_classes=num_fine_classes)\n",
        "\n",
        "# Define the maximum sequence length\n",
        "max_seq_length = 100\n",
        "\n",
        "# Add a <PAD> token at the end of each text sequence\n",
        "qa_df['padded_text'] = qa_df['text'].apply(lambda x: x + ['<PAD>'])\n",
        "\n",
        "# Get the embeddings for the padded text sequences\n",
        "X_text = qa_df['padded_text'].apply(get_text_embeddings)\n",
        "\n",
        "# Pad or truncate the 'text_embeddings' sequences to have the same length\n",
        "X_text = pad_sequences(X_text, maxlen=max_seq_length + 1, dtype='float32')\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (max_seq_length + 1, 300)\n",
        "\n",
        "# Create the input layer\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# Create the Bidirectional LSTM layer\n",
        "lstm_outputs = Bidirectional(LSTM(100, return_sequences=True))(inputs)\n",
        "\n",
        "# Create the coarse and fine output layers\n",
        "coarse_outputs = Dense(num_coarse_classes, activation='softmax')(lstm_outputs[:, -2, :])\n",
        "fine_outputs = Dense(num_fine_classes, activation='softmax')(lstm_outputs[:, -1, :])\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=inputs, outputs=[coarse_outputs, fine_outputs])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_text, [y_coarse, y_fine], epochs=50, batch_size=32)\n",
        "\n",
        "questions = ['How many people speak French?', 'What day is today?', 'Who will win the war?', 'Who is Italian first minister?', 'When World War II ended?', 'When Gandhi was assassinated?']\n",
        "\n",
        "for question in questions:\n",
        "    # Normalize and tokenize the question\n",
        "    tokens = normalize_and_tokenize(question)\n",
        "    # Add a <PAD> token at the end of the sequence\n",
        "    tokens.append('<PAD>')\n",
        "    # Get the embeddings for the tokens\n",
        "    embeddings = get_text_embeddings(tokens)\n",
        "    # Pad or truncate the sequence to have the same length as the input shape\n",
        "    embeddings = pad_sequences([embeddings], maxlen=max_seq_length + 1, dtype='float32')\n",
        "    # Predict the coarse and fine labels for the question\n",
        "    coarse_pred, fine_pred = model.predict(embeddings)\n",
        "    # Get the index of the predicted coarse and fine labels\n",
        "    coarse_index = np.argmax(coarse_pred)\n",
        "    fine_index = np.argmax(fine_pred)\n",
        "    # Find all rows in qa_df where 'label-coarse' == coarse_index and 'label-fine' == fine_index\n",
        "    rows = qa_df[(qa_df['label-coarse'] == coarse_index) & (qa_df['label-fine'] == fine_index)]\n",
        "    if len(rows) > 0:\n",
        "        # Select a random row from rows as an answer to this question.\n",
        "        answer_row = rows.sample(n=1)\n",
        "        answer_text = answer_row.iloc[0]['answer']\n",
        "        print(f\"Q: {question}\")\n",
        "        print(f\"A: {' '.join(answer_text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1K804r6TcnG",
        "outputId": "4b328763-726c-45eb-df43-01eeb1dd39f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 10s 271ms/step - loss: 5.2050 - dense_loss: 1.5668 - dense_1_loss: 3.6382 - dense_accuracy: 0.4220 - dense_1_accuracy: 0.2700\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 4s 261ms/step - loss: 3.8524 - dense_loss: 1.1233 - dense_1_loss: 2.7291 - dense_accuracy: 0.6520 - dense_1_accuracy: 0.4180\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 3.0258 - dense_loss: 0.8122 - dense_1_loss: 2.2136 - dense_accuracy: 0.7760 - dense_1_accuracy: 0.5080\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 4s 261ms/step - loss: 2.5422 - dense_loss: 0.6074 - dense_1_loss: 1.9348 - dense_accuracy: 0.8200 - dense_1_accuracy: 0.5280\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 2.0974 - dense_loss: 0.4098 - dense_1_loss: 1.6876 - dense_accuracy: 0.8860 - dense_1_accuracy: 0.5680\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.7395 - dense_loss: 0.2758 - dense_1_loss: 1.4637 - dense_accuracy: 0.9380 - dense_1_accuracy: 0.6120\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 4s 264ms/step - loss: 1.4628 - dense_loss: 0.1888 - dense_1_loss: 1.2740 - dense_accuracy: 0.9560 - dense_1_accuracy: 0.6620\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 1.2467 - dense_loss: 0.1446 - dense_1_loss: 1.1021 - dense_accuracy: 0.9740 - dense_1_accuracy: 0.7240\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 4s 261ms/step - loss: 1.0584 - dense_loss: 0.0994 - dense_1_loss: 0.9590 - dense_accuracy: 0.9860 - dense_1_accuracy: 0.7620\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 4s 260ms/step - loss: 0.9175 - dense_loss: 0.0845 - dense_1_loss: 0.8329 - dense_accuracy: 0.9920 - dense_1_accuracy: 0.8260\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.7538 - dense_loss: 0.0605 - dense_1_loss: 0.6933 - dense_accuracy: 0.9940 - dense_1_accuracy: 0.8440\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 4s 264ms/step - loss: 0.6437 - dense_loss: 0.0557 - dense_1_loss: 0.5880 - dense_accuracy: 0.9920 - dense_1_accuracy: 0.8760\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 4s 264ms/step - loss: 0.5200 - dense_loss: 0.0396 - dense_1_loss: 0.4804 - dense_accuracy: 0.9980 - dense_1_accuracy: 0.9060\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.4256 - dense_loss: 0.0349 - dense_1_loss: 0.3906 - dense_accuracy: 0.9980 - dense_1_accuracy: 0.9360\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 4s 264ms/step - loss: 0.3544 - dense_loss: 0.0293 - dense_1_loss: 0.3251 - dense_accuracy: 1.0000 - dense_1_accuracy: 0.9560\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 5s 298ms/step - loss: 0.2987 - dense_loss: 0.0249 - dense_1_loss: 0.2738 - dense_accuracy: 1.0000 - dense_1_accuracy: 0.9720\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.2471 - dense_loss: 0.0225 - dense_1_loss: 0.2246 - dense_accuracy: 1.0000 - dense_1_accuracy: 0.9760\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 4s 266ms/step - loss: 0.2106 - dense_loss: 0.0204 - dense_1_loss: 0.1902 - dense_accuracy: 1.0000 - dense_1_accuracy: 0.9860\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.1772 - dense_loss: 0.0173 - dense_1_loss: 0.1600 - dense_accuracy: 1.0000 - dense_1_accuracy: 0.9900\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 4s 264ms/step - loss: 0.1570 - dense_loss: 0.0163 - dense_1_loss: 0.1406 - dense_accuracy: 1.0000 - dense_1_accuracy: 0.9900\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 4s 261ms/step - loss: 0.1332 - dense_loss: 0.0143 - dense_1_loss: 0.1189 - dense_accuracy: 1.0000 - dense_1_accuracy: 0.9980\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.1139 - dense_loss: 0.0130 - dense_1_loss: 0.1009 - dense_accuracy: 1.0000 - dense_1_accuracy: 0.9980\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 4s 260ms/step - loss: 0.0988 - dense_loss: 0.0118 - dense_1_loss: 0.0870 - dense_accuracy: 1.0000 - dense_1_accuracy: 0.9980\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 4s 262ms/step - loss: 0.0882 - dense_loss: 0.0108 - dense_1_loss: 0.0774 - dense_accuracy: 1.0000 - dense_1_accuracy: 0.9980\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.0792 - dense_loss: 0.0101 - dense_1_loss: 0.0691 - dense_accuracy: 1.0000 - dense_1_accuracy: 0.9980\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 4s 264ms/step - loss: 0.0705 - dense_loss: 0.0089 - dense_1_loss: 0.0615 - dense_accuracy: 1.0000 - dense_1_accuracy: 0.9980\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 0.0630 - dense_loss: 0.0083 - dense_1_loss: 0.0547 - dense_accuracy: 1.0000 - dense_1_accuracy: 0.9980\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 0.0583 - dense_loss: 0.0077 - dense_1_loss: 0.0505 - dense_accuracy: 1.0000 - dense_1_accuracy: 0.9980\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.0524 - dense_loss: 0.0071 - dense_1_loss: 0.0453 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.0479 - dense_loss: 0.0066 - dense_1_loss: 0.0412 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 4s 263ms/step - loss: 0.0434 - dense_loss: 0.0063 - dense_1_loss: 0.0371 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 4s 276ms/step - loss: 0.0400 - dense_loss: 0.0059 - dense_1_loss: 0.0341 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 6s 340ms/step - loss: 0.0377 - dense_loss: 0.0055 - dense_1_loss: 0.0322 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 4s 264ms/step - loss: 0.0346 - dense_loss: 0.0052 - dense_1_loss: 0.0295 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 5s 350ms/step - loss: 0.0323 - dense_loss: 0.0050 - dense_1_loss: 0.0273 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 5s 275ms/step - loss: 0.0305 - dense_loss: 0.0047 - dense_1_loss: 0.0258 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 4s 275ms/step - loss: 0.0284 - dense_loss: 0.0044 - dense_1_loss: 0.0241 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 0.0266 - dense_loss: 0.0042 - dense_1_loss: 0.0224 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 5s 293ms/step - loss: 0.0251 - dense_loss: 0.0040 - dense_1_loss: 0.0211 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 5s 342ms/step - loss: 0.0236 - dense_loss: 0.0038 - dense_1_loss: 0.0199 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 6s 331ms/step - loss: 0.0224 - dense_loss: 0.0036 - dense_1_loss: 0.0188 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 4s 277ms/step - loss: 0.0213 - dense_loss: 0.0035 - dense_1_loss: 0.0178 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 0.0202 - dense_loss: 0.0033 - dense_1_loss: 0.0169 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 0.0191 - dense_loss: 0.0032 - dense_1_loss: 0.0160 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 0.0183 - dense_loss: 0.0030 - dense_1_loss: 0.0152 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.0174 - dense_loss: 0.0029 - dense_1_loss: 0.0145 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 0.0166 - dense_loss: 0.0028 - dense_1_loss: 0.0139 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 0.0159 - dense_loss: 0.0027 - dense_1_loss: 0.0133 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 0.0152 - dense_loss: 0.0026 - dense_1_loss: 0.0127 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 0.0147 - dense_loss: 0.0025 - dense_1_loss: 0.0122 - dense_accuracy: 1.0000 - dense_1_accuracy: 1.0000\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "Q: What day is today?\n",
            "A: developmental disorder\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Q: Who will win the war?\n",
            "A: grover cleveland\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "Q: Who is Italian first minister?\n",
            "A: jackie robinson\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "Q: When World War II ended?\n",
            "A: 1945\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Q: When Gandhi was assassinated?\n",
            "A: 1789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = ['How many people speak French?', 'What day is today?', 'Who will win the war?', 'Who is Italian first minister?', 'When World War II ended?', 'When Gandhi was assassinated?']\n",
        "\n",
        "for question in questions:\n",
        "    # Normalize and tokenize the question\n",
        "    tokens = normalize_and_tokenize(question)\n",
        "    # Add a <PAD> token at the end of the sequence\n",
        "    tokens.append('<PAD>')\n",
        "    # Get the embeddings for the tokens\n",
        "    embeddings = get_text_embeddings(tokens)\n",
        "    # Pad or truncate the sequence to have the same length as the input shape\n",
        "    embeddings = pad_sequences([embeddings], maxlen=max_seq_length + 1, dtype='float32')\n",
        "    # Predict the coarse and fine labels for the question\n",
        "    coarse_pred, fine_pred = model.predict(embeddings)\n",
        "    # Get the index of the predicted coarse and fine labels\n",
        "    coarse_index = np.argmax(coarse_pred)\n",
        "    fine_index = np.argmax(fine_pred)\n",
        "    # Find all rows in qa_df where 'label-coarse' == coarse_index and 'label-fine' == fine_index\n",
        "    rows = qa_df[(qa_df['label-coarse'] == coarse_index) & (qa_df['label-fine'] == fine_index)]\n",
        "    if len(rows) > 0:\n",
        "        # Select a random row from rows as an answer to this question.\n",
        "        answer_row = rows.sample(n=1)\n",
        "        answer_text = answer_row.iloc[0]['answer']\n",
        "        print(f\"Q: {question}\")\n",
        "        print(f\"A: {' '.join(answer_text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CioMJQdOWHsb",
        "outputId": "e3e9a1d0-68ca-4b5d-bad0-1fb450dfa32f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 113ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "Q: What day is today?\n",
            "A: measures temperature\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "Q: Who will win the war?\n",
            "A: chris haney and scott abbott\n",
            "1/1 [==============================] - 0s 161ms/step\n",
            "Q: Who is Italian first minister?\n",
            "A: the bard\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "Q: When World War II ended?\n",
            "A: 1789\n",
            "1/1 [==============================] - 0s 178ms/step\n",
            "Q: When Gandhi was assassinated?\n",
            "A: 1939\n"
          ]
        }
      ]
    }
  ]
}